{'state': {}, 'param_groups': [{'lr': 0.0003, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'differentiable': False, 'fused': None, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]}]}
Traceback (most recent call last):                                                                                     
  File "C:\Users\luism\OneDrive\Escritorio\DesktopML\finalTumorDetection\train.py", line 175, in <module>
    epoch_acc, epoch_loss = model_training(model, train_loader, optimizer, loss_fn,device)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luism\OneDrive\Escritorio\DesktopML\finalTumorDetection\train.py", line 107, in model_training
    loss.backward()
  File "C:\Users\luism\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\_tensor.py", line 521, in backward
    torch.autograd.backward(
  File "C:\Users\luism\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\autograd\__init__.py", line 289, in backward
    _engine_run_backward(
  File "C:\Users\luism\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\autograd\graph.py", line 769, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
